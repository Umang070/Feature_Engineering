{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data, \n",
    "text data is definitely one of the most abundant sources of unstructured data. Text data usually consists of documents which can represent words, sentences or even paragraphs of free flowing text. The inherent unstructured (no neatly formatted data columns!) and noisy nature of textual data makes it harder for machine learning methods to directly work on raw text data.\n",
    "\n",
    "\n",
    "The importance of feature engineering is even more important for unstructured, textual data because we need to convert free flowing text into some numeric representations which can then be understood by machine learning algorithms\n",
    "\n",
    "\n",
    "“If you are given a box of tools to repair a house, you should know when to use a power drill and when to use a hammer!”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem with Text\n",
    "A problem with modeling text is that it is messy, and techniques like machine learning algorithms prefer well defined fixed-length inputs and outputs.\n",
    "\n",
    "Machine learning algorithms cannot work with raw text directly; the text must be converted into numbers. Specifically, vectors of numbers.\n",
    "\n",
    "In language processing, the vectors x are derived from textual data, in order to reflect various linguistic properties of the text.\n",
    "\n",
    "\n",
    "\n",
    "This is called feature extraction or feature encoding.\n",
    "\n",
    "A popular and simple method of feature extraction with text data is called the bag-of-words model of text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a Bag-of-Words?\n",
    "A bag-of-words model, or BoW for short, is a way of extracting features from text for use in modeling, such as with machine learning algorithms.\n",
    "\n",
    "The approach is very simple and flexible, and can be used in a myriad of ways for extracting features from documents.\n",
    "\n",
    "A bag-of-words is a representation of text that describes the occurrence of words within a document. It involves two things:\n",
    "\n",
    "A vocabulary of known words.\n",
    "A measure of the presence of known words.\n",
    "It is called a “bag” of words, because any information about the order or structure of words in the document is discarded. The model is only concerned with whether known words occur in the document, not where in the document.\n",
    "\n",
    "\"A very common feature extraction procedures for sentences and documents is the bag-of-words approach (BOW). In this approach, we look at the histogram of the words within the text, i.e. considering each word count as a feature.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "pd.options.display.max_colwidth = None\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sky is blue and beautiful.</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this blue and beautiful sky!</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
       "      <td>weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The dog is lazy but the brown fox is quick!</td>\n",
       "      <td>animals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Document    label\n",
       "0                                      The sky is blue and beautiful.  weather\n",
       "1                                   Love this blue and beautiful sky!  weather\n",
       "2                        The quick brown fox jumps over the lazy dog.  animals\n",
       "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans     food\n",
       "4                         I love green eggs, ham, sausages and bacon!     food\n",
       "5                    The brown fox is quick and the blue dog is lazy!  animals\n",
       "6            The sky is very blue and the sky is very beautiful today  weather\n",
       "7                         The dog is lazy but the brown fox is quick!  animals"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = ['The sky is blue and beautiful.',\n",
    "          'Love this blue and beautiful sky!',\n",
    "          'The quick brown fox jumps over the lazy dog.',\n",
    "          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
    "          'I love green eggs, ham, sausages and bacon!',\n",
    "          'The brown fox is quick and the blue dog is lazy!',\n",
    "          'The sky is very blue and the sky is very beautiful today',\n",
    "          'The dog is lazy but the brown fox is quick!'    \n",
    "]\n",
    "labels = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals']\n",
    "\n",
    "df = pd.DataFrame({'Document':corpus, 'label':labels})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Removing Extra Space  \n",
    "\n",
    "Removing special characters \n",
    "\n",
    "Ignoring case\n",
    "Ignoring punctuation\n",
    "\n",
    "Ignoring frequent words that don’t contain much information, called stop words, like “a,” “of,” etc.\n",
    "\n",
    "Fixing misspelled words.\n",
    "Reducing words to their stem (e.g. “play” from “playing”) using stemming algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpt = nltk.WordPunctTokenizer()\n",
    "# nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "#     print(doc)\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()  #lower case\n",
    "    doc = doc.strip()  #white space \n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    \n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "#     print(filtered_tokens)\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sky blue beautiful', 'love blue beautiful sky',\n",
       "       'quick brown fox jumps lazy dog',\n",
       "       'kings breakfast sausages ham bacon eggs toast beans',\n",
       "       'love green eggs ham sausages bacon',\n",
       "       'brown fox quick blue dog lazy', 'sky blue sky beautiful today',\n",
       "       'dog lazy brown fox quick'], dtype='<U51')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once we have our basic pre-processing pipeline ready, let’s apply the same to our sample corpus.\n",
    "normalize_corpus = np.vectorize(normalize_document)(corpus)\n",
    "normalize_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bacon</th>\n",
       "      <th>beans</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>blue</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>eggs</th>\n",
       "      <th>fox</th>\n",
       "      <th>green</th>\n",
       "      <th>ham</th>\n",
       "      <th>jumps</th>\n",
       "      <th>kings</th>\n",
       "      <th>lazy</th>\n",
       "      <th>love</th>\n",
       "      <th>quick</th>\n",
       "      <th>sausages</th>\n",
       "      <th>sky</th>\n",
       "      <th>toast</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bacon  beans  beautiful  blue  breakfast  brown  dog  eggs  fox  green  \\\n",
       "0      0      0          1     1          0      0    0     0    0      0   \n",
       "1      0      0          1     1          0      0    0     0    0      0   \n",
       "2      0      0          0     0          0      1    1     0    1      0   \n",
       "3      1      1          0     0          1      0    0     1    0      0   \n",
       "4      1      0          0     0          0      0    0     1    0      1   \n",
       "5      0      0          0     1          0      1    1     0    1      0   \n",
       "6      0      0          1     1          0      0    0     0    0      0   \n",
       "7      0      0          0     0          0      1    1     0    1      0   \n",
       "\n",
       "   ham  jumps  kings  lazy  love  quick  sausages  sky  toast  today  \n",
       "0    0      0      0     0     0      0         0    1      0      0  \n",
       "1    0      0      0     0     1      0         0    1      0      0  \n",
       "2    0      1      0     1     0      1         0    0      0      0  \n",
       "3    1      0      1     0     0      0         1    0      1      0  \n",
       "4    1      0      0     0     1      0         1    0      0      0  \n",
       "5    0      0      0     1     0      1         0    0      0      0  \n",
       "6    0      0      0     0     0      0         0    2      0      1  \n",
       "7    0      0      0     1     0      1         0    0      0      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "cv_matrix = cv.fit_transform(normalize_corpus)\n",
    "cv_matrix=cv_matrix.todense()\n",
    "vocabulary = cv.get_feature_names()\n",
    "\n",
    "cv_df = pd.DataFrame(cv_matrix, columns=vocabulary)\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Bags of N gram Model\n",
    "An N-gram is basically a collection of word tokens from a text document such that these tokens are contiguous and occur in a sequence. Bi-grams indicate n-grams of order 2 (two words), Tri-grams indicate n-grams of order 3 (three words), and so on. The Bag of N-Grams model is hence just an extension of the Bag of Words model so we can also leverage N-gram based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bacon eggs</th>\n",
       "      <th>beautiful sky</th>\n",
       "      <th>beautiful today</th>\n",
       "      <th>blue beautiful</th>\n",
       "      <th>blue dog</th>\n",
       "      <th>blue sky</th>\n",
       "      <th>breakfast sausages</th>\n",
       "      <th>brown fox</th>\n",
       "      <th>dog lazy</th>\n",
       "      <th>eggs ham</th>\n",
       "      <th>...</th>\n",
       "      <th>lazy dog</th>\n",
       "      <th>love blue</th>\n",
       "      <th>love green</th>\n",
       "      <th>quick blue</th>\n",
       "      <th>quick brown</th>\n",
       "      <th>sausages bacon</th>\n",
       "      <th>sausages ham</th>\n",
       "      <th>sky beautiful</th>\n",
       "      <th>sky blue</th>\n",
       "      <th>toast beans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bacon eggs  beautiful sky  beautiful today  blue beautiful  blue dog  \\\n",
       "0           0              0                0               1         0   \n",
       "1           0              1                0               1         0   \n",
       "2           0              0                0               0         0   \n",
       "3           1              0                0               0         0   \n",
       "4           0              0                0               0         0   \n",
       "5           0              0                0               0         1   \n",
       "6           0              0                1               0         0   \n",
       "7           0              0                0               0         0   \n",
       "\n",
       "   blue sky  breakfast sausages  brown fox  dog lazy  eggs ham  ...  lazy dog  \\\n",
       "0         0                   0          0         0         0  ...         0   \n",
       "1         0                   0          0         0         0  ...         0   \n",
       "2         0                   0          1         0         0  ...         1   \n",
       "3         0                   1          0         0         0  ...         0   \n",
       "4         0                   0          0         0         1  ...         0   \n",
       "5         0                   0          1         1         0  ...         0   \n",
       "6         1                   0          0         0         0  ...         0   \n",
       "7         0                   0          1         1         0  ...         0   \n",
       "\n",
       "   love blue  love green  quick blue  quick brown  sausages bacon  \\\n",
       "0          0           0           0            0               0   \n",
       "1          1           0           0            0               0   \n",
       "2          0           0           0            1               0   \n",
       "3          0           0           0            0               0   \n",
       "4          0           1           0            0               1   \n",
       "5          0           0           1            0               0   \n",
       "6          0           0           0            0               0   \n",
       "7          0           0           0            0               0   \n",
       "\n",
       "   sausages ham  sky beautiful  sky blue  toast beans  \n",
       "0             0              0         1            0  \n",
       "1             0              0         0            0  \n",
       "2             0              0         0            0  \n",
       "3             1              0         0            1  \n",
       "4             0              0         0            0  \n",
       "5             0              0         0            0  \n",
       "6             0              1         1            0  \n",
       "7             0              0         0            0  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can set the n-gram range to 1,2 to get unigrams as well as bigrams\n",
    "bv = CountVectorizer(ngram_range=(2,2))\n",
    "bv_matrix = bv.fit_transform(normalize_corpus)\n",
    "\n",
    "bv_matrix = bv_matrix.toarray()\n",
    "vocab = bv.get_feature_names()\n",
    "bv_df = pd.DataFrame(bv_matrix, columns=vocab)\n",
    "bv_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Model\n",
    "\n",
    "TF: Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization:\n",
    "\n",
    "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "\n",
    "IDF: Inverse Document Frequency, which measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following:\n",
    "\n",
    "IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
    "\n",
    "See below for a simple example.\n",
    "\n",
    "Example:\n",
    "\n",
    "Consider a document containing 100 words wherein the word cat appears 3 times. The term frequency (i.e., tf) for cat is then (3 / 100) = 0.03. Now, assume we have 10 million documents and the word cat appears in one thousand of these. Then, the inverse document frequency (i.e., idf) is calculated as log(10,000,000 / 1,000) = 4. Thus, the Tf-idf weight is the product of these quantities: 0.03 * 4 = 0.12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bacon</th>\n",
       "      <th>beans</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>blue</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>eggs</th>\n",
       "      <th>fox</th>\n",
       "      <th>green</th>\n",
       "      <th>ham</th>\n",
       "      <th>jumps</th>\n",
       "      <th>kings</th>\n",
       "      <th>lazy</th>\n",
       "      <th>love</th>\n",
       "      <th>quick</th>\n",
       "      <th>sausages</th>\n",
       "      <th>sky</th>\n",
       "      <th>toast</th>\n",
       "      <th>today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bacon  beans  beautiful  blue  breakfast  brown   dog  eggs   fox  green  \\\n",
       "0   0.00   0.00       0.60  0.53       0.00   0.00  0.00  0.00  0.00   0.00   \n",
       "1   0.00   0.00       0.49  0.43       0.00   0.00  0.00  0.00  0.00   0.00   \n",
       "2   0.00   0.00       0.00  0.00       0.00   0.38  0.38  0.00  0.38   0.00   \n",
       "3   0.32   0.38       0.00  0.00       0.38   0.00  0.00  0.32  0.00   0.00   \n",
       "4   0.39   0.00       0.00  0.00       0.00   0.00  0.00  0.39  0.00   0.47   \n",
       "5   0.00   0.00       0.00  0.37       0.00   0.42  0.42  0.00  0.42   0.00   \n",
       "6   0.00   0.00       0.36  0.32       0.00   0.00  0.00  0.00  0.00   0.00   \n",
       "7   0.00   0.00       0.00  0.00       0.00   0.45  0.45  0.00  0.45   0.00   \n",
       "\n",
       "    ham  jumps  kings  lazy  love  quick  sausages   sky  toast  today  \n",
       "0  0.00   0.00   0.00  0.00  0.00   0.00      0.00  0.60   0.00    0.0  \n",
       "1  0.00   0.00   0.00  0.00  0.57   0.00      0.00  0.49   0.00    0.0  \n",
       "2  0.00   0.53   0.00  0.38  0.00   0.38      0.00  0.00   0.00    0.0  \n",
       "3  0.32   0.00   0.38  0.00  0.00   0.00      0.32  0.00   0.38    0.0  \n",
       "4  0.39   0.00   0.00  0.00  0.39   0.00      0.39  0.00   0.00    0.0  \n",
       "5  0.00   0.00   0.00  0.42  0.00   0.42      0.00  0.00   0.00    0.0  \n",
       "6  0.00   0.00   0.00  0.00  0.00   0.00      0.00  0.72   0.00    0.5  \n",
       "7  0.00   0.00   0.00  0.45  0.00   0.45      0.00  0.00   0.00    0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
    "tv_matrix = tv.fit_transform(normalize_corpus)\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "vocab = tv.get_feature_names()\n",
    "tv_df=pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)\n",
    "tv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Similarity\n",
    "Document similarity is the process of using a distance or similarity based metric that can be used to identify how similar a text document is with any other document(s) based on features extracted from the documents like bag of words or tf-idf.\n",
    "\n",
    "Pairwise document similarity in a corpus involves computing document similarity for each pair of documents in a corpus. Thus if you have C documents in a corpus, you would end up with a C x C matrix such that each row and column represents the similarity score for a pair of documents, which represent the indices at the row and column, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.820599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192353</td>\n",
       "      <td>0.817246</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.820599</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225489</td>\n",
       "      <td>0.157845</td>\n",
       "      <td>0.670631</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.506866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506866</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.192353</td>\n",
       "      <td>0.157845</td>\n",
       "      <td>0.791821</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.115488</td>\n",
       "      <td>0.930989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.817246</td>\n",
       "      <td>0.670631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115488</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.820599  0.000000  0.000000  0.000000  0.192353  0.817246   \n",
       "1  0.820599  1.000000  0.000000  0.000000  0.225489  0.157845  0.670631   \n",
       "2  0.000000  0.000000  1.000000  0.000000  0.000000  0.791821  0.000000   \n",
       "3  0.000000  0.000000  0.000000  1.000000  0.506866  0.000000  0.000000   \n",
       "4  0.000000  0.225489  0.000000  0.506866  1.000000  0.000000  0.000000   \n",
       "5  0.192353  0.157845  0.791821  0.000000  0.000000  1.000000  0.115488   \n",
       "6  0.817246  0.670631  0.000000  0.000000  0.000000  0.115488  1.000000   \n",
       "7  0.000000  0.000000  0.850516  0.000000  0.000000  0.930989  0.000000   \n",
       "\n",
       "          7  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.850516  \n",
       "3  0.000000  \n",
       "4  0.000000  \n",
       "5  0.930989  \n",
       "6  0.000000  \n",
       "7  1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(tv_matrix)\n",
    "similarity_df = pd.DataFrame(similarity_matrix)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity basically gives us a metric representing the cosine of the angle between the feature vector representations of two text documents. Lower the angle between the documents, the closer and more similar they are.\n",
    "\n",
    "\n",
    "Looking closely at the similarity matrix clearly tells us that documents (0, 1 and 6), (2, 5 and 7) are very similar to one another and documents 3 and 4 are slightly similar to each other but the magnitude is not very strong, however still stronger than the other documents. This must indicate these similar documents have some similar features. This is a perfect example of grouping or clustering that can be solved by unsupervised learning especially when you are dealing with huge corpora of millions of text documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Clustering with Similarity Features\n",
    "Clustering leverages unsupervised learning to group data points (documents in this scenario) into groups or clusters. We will be leveraging an unsupervised hierarchical clustering algorithm here to try and group similar documents from our toy corpus together by leveraging the document similarity features we generated earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document\\Cluster 1</th>\n",
       "      <th>Document\\Cluster 2</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Cluster Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.253098</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.308539</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.386952</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.489845</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.732945</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>2.69565</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>3.45108</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Document\\Cluster 1 Document\\Cluster 2  Distance Cluster Size\n",
       "0                  2                  7  0.253098            2\n",
       "1                  0                  6  0.308539            2\n",
       "2                  5                  8  0.386952            3\n",
       "3                  1                  9  0.489845            3\n",
       "4                  3                  4  0.732945            2\n",
       "5                 11                 12   2.69565            5\n",
       "6                 10                 13   3.45108            8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "Z = linkage(similarity_matrix, 'ward')\n",
    "Z_df = pd.DataFrame(Z, columns=['Document\\Cluster 1', 'Document\\Cluster 2', \n",
    "                         'Distance', 'Cluster Size'], dtype='object')\n",
    "Z_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you closely look at the linkage matrix, you can see that each step (row) of the linkage matrix tells us which data points (or clusters) were merged together. If you have n data points, the linkage matrix, Z will be having a shape of (n — 1) x 4 where Z[i] will tell us which clusters were merged at step i. Each row has four elements, the first two elements are either data point identifiers or cluster labels (in the later parts of the matrix once\n",
    "multiple data points are merged), the third element is the cluster distance between the first two elements (either data points or clusters), and the last element is the total number of elements\\data points in the cluster once the merge is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x21cc36583c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Data point')\n",
    "plt.ylabel('Distance')\n",
    "dn = dendrogram(Z)\n",
    "plt.axhline(y=1.0, color='k', ls='-', lw=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>label</th>\n",
       "      <th>Cluster_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sky is blue and beautiful.</td>\n",
       "      <td>weather</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this blue and beautiful sky!</td>\n",
       "      <td>weather</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>animals</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
       "      <td>food</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
       "      <td>food</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
       "      <td>animals</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
       "      <td>weather</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The dog is lazy but the brown fox is quick!</td>\n",
       "      <td>animals</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Document  \\\n",
       "0                                      The sky is blue and beautiful.   \n",
       "1                                   Love this blue and beautiful sky!   \n",
       "2                        The quick brown fox jumps over the lazy dog.   \n",
       "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans   \n",
       "4                         I love green eggs, ham, sausages and bacon!   \n",
       "5                    The brown fox is quick and the blue dog is lazy!   \n",
       "6            The sky is very blue and the sky is very beautiful today   \n",
       "7                         The dog is lazy but the brown fox is quick!   \n",
       "\n",
       "     label  Cluster_label  \n",
       "0  weather              2  \n",
       "1  weather              2  \n",
       "2  animals              1  \n",
       "3     food              3  \n",
       "4     food              3  \n",
       "5  animals              1  \n",
       "6  weather              2  \n",
       "7  animals              1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "max_dist = 1.0\n",
    "cl_label = fcluster(Z, max_dist, criterion='distance')\n",
    "cl_label_df = pd.DataFrame(cl_label, columns=['Cluster_label'])\n",
    "pd.concat([df,cl_label_df],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Models\n",
    "We can also use some summarization techniques to extract topic or concept based features from text documents. The idea of topic models revolves around the process of extracting key themes or concepts from a corpus of documents which are represented as topics. Each topic can be represented as a bag or collection of words/terms from the document corpus. Together, these terms signify a specific topic, theme or a concept and each topic can be easily distinguished from other topics by virtue of the semantic meaning conveyed by these terms. However often you do end up with overlapping topics based on the data. These concepts can range from simple facts and statements to opinions and outlook. Topic models are extremely useful in summarizing large corpus of text documents to extract and depict key concepts. They are also useful in extracting features from text data that capture latent patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of feature engineering which is the intent of this article, you need to remember that when LDA is applied on a document-term matrix (TF-IDF or Bag of Words feature matrix), it gets decomposed into two main components.\n",
    "A document-topic matrix, which would be the feature matrix we\n",
    "are looking for.\n",
    "A topic-term matrix, which helps us in looking at potential topics in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document - Topic Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.832191</td>\n",
       "      <td>0.083480</td>\n",
       "      <td>0.084329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.863554</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>0.067346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.047794</td>\n",
       "      <td>0.047776</td>\n",
       "      <td>0.904430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037243</td>\n",
       "      <td>0.925559</td>\n",
       "      <td>0.037198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.049121</td>\n",
       "      <td>0.903076</td>\n",
       "      <td>0.047802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.047778</td>\n",
       "      <td>0.897321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.888287</td>\n",
       "      <td>0.055697</td>\n",
       "      <td>0.056016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.055704</td>\n",
       "      <td>0.055689</td>\n",
       "      <td>0.888607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         T1        T2        T3\n",
       "0  0.832191  0.083480  0.084329\n",
       "1  0.863554  0.069100  0.067346\n",
       "2  0.047794  0.047776  0.904430\n",
       "3  0.037243  0.925559  0.037198\n",
       "4  0.049121  0.903076  0.047802\n",
       "5  0.054902  0.047778  0.897321\n",
       "6  0.888287  0.055697  0.056016\n",
       "7  0.055704  0.055689  0.888607"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=3, max_iter=10000, random_state=0)\n",
    "dt_matrix = lda.fit_transform(cv_matrix)\n",
    "features_matrix = pd.DataFrame(dt_matrix, columns=['T1', 'T2', 'T3'])\n",
    "features_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sky', 4.3324394424701325), ('blue', 3.373774254787669), ('beautiful', 3.3323650509884386), ('today', 1.3325579855138987), ('love', 1.330415818217548)]\n",
      "\n",
      "[('bacon', 2.33269586574902), ('eggs', 2.33269586574902), ('ham', 2.33269586574902), ('sausages', 2.33269586574902), ('love', 1.3354610533796556), ('beans', 1.3327735190105536), ('breakfast', 1.3327735190105536), ('kings', 1.3327735190105536), ('toast', 1.3327735190105536), ('green', 1.3325431515674175)]\n",
      "\n",
      "[('brown', 3.3323473548404405), ('dog', 3.3323473548404405), ('fox', 3.3323473548404405), ('lazy', 3.3323473548404405), ('quick', 3.3323473548404405), ('jumps', 1.3324193772908193), ('blue', 1.2919423137963386)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_term_matrix = lda.components_\n",
    "\n",
    "\n",
    "for topic_weights in topic_term_matrix:\n",
    "\n",
    "    topic = [(token, weight) for token, weight in zip(vocabulary, topic_weights)]  # list of tuple (token and associated weight)\n",
    "    topic = sorted(topic, key=lambda x:x[1], reverse=True)  #or -x[1]\n",
    "    topic = [item for item in topic if item[1] > 0.6]\n",
    "    print(topic)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hus you can clearly see the three topics are quite distinguishable from each other based on their constituent terms, first one talking about weather, second one about food and the last one about animals. Choosing the number of topics for topic modeling is an entire topic on its own (pun not intended!) and is an art as well as a science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Clustering with Topic Model Features[Document_Topic Matrix]\n",
    "We used our Bag of Words model based features to build out topic model based features using LDA. We can now actually leverage the document term matrix we obtained and use an unsupervised clustering algorithm to try and group our documents similar to what we did earlier with our similarity features.\n",
    "\n",
    "\n",
    "We will use a very popular partition based clustering method this time, K-means clustering to cluster or group these documents based on their topic model feature representations. In K-means clustering, we have an input parameter k, which specifies the number of clusters it will output using the document features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>label</th>\n",
       "      <th>Cluster Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The sky is blue and beautiful.</td>\n",
       "      <td>weather</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this blue and beautiful sky!</td>\n",
       "      <td>weather</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
       "      <td>animals</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A king's breakfast has sausages, ham, bacon, eggs, toast and beans</td>\n",
       "      <td>food</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
       "      <td>food</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
       "      <td>animals</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The sky is very blue and the sky is very beautiful today</td>\n",
       "      <td>weather</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The dog is lazy but the brown fox is quick!</td>\n",
       "      <td>animals</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Document  \\\n",
       "0                                      The sky is blue and beautiful.   \n",
       "1                                   Love this blue and beautiful sky!   \n",
       "2                        The quick brown fox jumps over the lazy dog.   \n",
       "3  A king's breakfast has sausages, ham, bacon, eggs, toast and beans   \n",
       "4                         I love green eggs, ham, sausages and bacon!   \n",
       "5                    The brown fox is quick and the blue dog is lazy!   \n",
       "6            The sky is very blue and the sky is very beautiful today   \n",
       "7                         The dog is lazy but the brown fox is quick!   \n",
       "\n",
       "     label  Cluster Label  \n",
       "0  weather              2  \n",
       "1  weather              2  \n",
       "2  animals              1  \n",
       "3     food              0  \n",
       "4     food              0  \n",
       "5  animals              1  \n",
       "6  weather              2  \n",
       "7  animals              1  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=1)\n",
    "kmeans.fit(features_matrix)\n",
    "cluster_labels=kmeans.labels_\n",
    "cluster_center = kmeans.cluster_centers_\n",
    "cluster_labels_df = pd.DataFrame(cluster_labels, columns=['Cluster Label'])\n",
    "pd.concat([df,cluster_labels_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
